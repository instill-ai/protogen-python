"""
@generated by mypy-protobuf.  Do not edit manually!
isort:skip_file
"""
import builtins
import collections.abc
import google.protobuf.descriptor
import google.protobuf.internal.containers
import google.protobuf.message
import google.protobuf.struct_pb2
import model.model.v1alpha.common_pb2
import sys
import typing

if sys.version_info >= (3, 8):
    import typing as typing_extensions
else:
    import typing_extensions

DESCRIPTOR: google.protobuf.descriptor.FileDescriptor

@typing_extensions.final
class TextGenerationChatInput(google.protobuf.message.Message):
    """TextGenerationChatInput represents the input of a text generation chat task."""

    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    PROMPT_FIELD_NUMBER: builtins.int
    PROMPT_IMAGES_FIELD_NUMBER: builtins.int
    CHAT_HISTORY_FIELD_NUMBER: builtins.int
    SYSTEM_MESSAGE_FIELD_NUMBER: builtins.int
    MAX_NEW_TOKENS_FIELD_NUMBER: builtins.int
    TEMPERATURE_FIELD_NUMBER: builtins.int
    TOP_K_FIELD_NUMBER: builtins.int
    SEED_FIELD_NUMBER: builtins.int
    EXTRA_PARAMS_FIELD_NUMBER: builtins.int
    prompt: builtins.str
    """Prompt text."""
    @property
    def prompt_images(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[model.model.v1alpha.common_pb2.PromptImage]:
        """Prompt images."""
    @property
    def chat_history(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[model.model.v1alpha.common_pb2.Message]:
        """Chat history."""
    system_message: builtins.str
    """System message, which sets the behaviour of the assistant."""
    max_new_tokens: builtins.int
    """Maximum number of generation tokens."""
    temperature: builtins.float
    """Sampling temperature."""
    top_k: builtins.int
    """Sampling Top K, number of tokens at the top from which the model will
    sample.
    """
    seed: builtins.int
    """Seed."""
    @property
    def extra_params(self) -> google.protobuf.struct_pb2.Struct:
        """Extra parameters."""
    def __init__(
        self,
        *,
        prompt: builtins.str = ...,
        prompt_images: collections.abc.Iterable[model.model.v1alpha.common_pb2.PromptImage] | None = ...,
        chat_history: collections.abc.Iterable[model.model.v1alpha.common_pb2.Message] | None = ...,
        system_message: builtins.str | None = ...,
        max_new_tokens: builtins.int | None = ...,
        temperature: builtins.float | None = ...,
        top_k: builtins.int | None = ...,
        seed: builtins.int | None = ...,
        extra_params: google.protobuf.struct_pb2.Struct | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["_max_new_tokens", b"_max_new_tokens", "_seed", b"_seed", "_system_message", b"_system_message", "_temperature", b"_temperature", "_top_k", b"_top_k", "extra_params", b"extra_params", "max_new_tokens", b"max_new_tokens", "seed", b"seed", "system_message", b"system_message", "temperature", b"temperature", "top_k", b"top_k"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["_max_new_tokens", b"_max_new_tokens", "_seed", b"_seed", "_system_message", b"_system_message", "_temperature", b"_temperature", "_top_k", b"_top_k", "chat_history", b"chat_history", "extra_params", b"extra_params", "max_new_tokens", b"max_new_tokens", "prompt", b"prompt", "prompt_images", b"prompt_images", "seed", b"seed", "system_message", b"system_message", "temperature", b"temperature", "top_k", b"top_k"]) -> None: ...
    @typing.overload
    def WhichOneof(self, oneof_group: typing_extensions.Literal["_max_new_tokens", b"_max_new_tokens"]) -> typing_extensions.Literal["max_new_tokens"] | None: ...
    @typing.overload
    def WhichOneof(self, oneof_group: typing_extensions.Literal["_seed", b"_seed"]) -> typing_extensions.Literal["seed"] | None: ...
    @typing.overload
    def WhichOneof(self, oneof_group: typing_extensions.Literal["_system_message", b"_system_message"]) -> typing_extensions.Literal["system_message"] | None: ...
    @typing.overload
    def WhichOneof(self, oneof_group: typing_extensions.Literal["_temperature", b"_temperature"]) -> typing_extensions.Literal["temperature"] | None: ...
    @typing.overload
    def WhichOneof(self, oneof_group: typing_extensions.Literal["_top_k", b"_top_k"]) -> typing_extensions.Literal["top_k"] | None: ...

global___TextGenerationChatInput = TextGenerationChatInput

@typing_extensions.final
class TextGenerationChatOutput(google.protobuf.message.Message):
    """TextGenerationChatOutput contains the result of a text generation chat task."""

    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    TEXT_FIELD_NUMBER: builtins.int
    text: builtins.str
    """Text generated by the model."""
    def __init__(
        self,
        *,
        text: builtins.str = ...,
    ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["text", b"text"]) -> None: ...

global___TextGenerationChatOutput = TextGenerationChatOutput
